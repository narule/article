---
layout: post
title: '人工智能AI发展及前景'
date: 2024-04-23 21:30:00 +0800
author: Sntree
categories: [AI]
tags: [AI, 服人工智能务, LLM, 大数据, 模型训练]
image: https://astree.oss-cn-shanghai.aliyuncs.com/sntree/wf_AI.jpg
top: true
---



## 人工智能定义

Artificial Intelligence  研究用于模拟、扩展人的智能的理论、方法、技术

更直白的说，就是模拟生物对外界不同环境现象能做出类似生物的反应（目前主要指人方面 像人一样回答问题，计算结果，分析数据，完成一些工作）

比如我们平时做事，学习编程，遇到问题请教老师，老师会解答问题以及告诉我们如何去做

现在的很多聊天模型LLM就可以做到模拟一个老师助手，回答提问者的问题给出解答。 这就是模拟人做一些事。

## 人工智能算法
因为需要模拟人，要实现在各种复杂场景都能应对，因此有了很多不同的算法，常见的有线性回归 逻辑回归 人工神经网络 决策树 随机森林 朴素贝叶斯等。
这些算法都是为了在外界有输入时（包括不限于文字提问，感知外界光线，声音等），作出准确分析，合理回答。

线性和大数据相当于是我们人的记忆，是什么就是什么，主要用于大量数据的检索和读取


而神经网络相较于大数据则是相反没有记忆，而是模拟神经元，主要体现在模拟思维，通过不同的输入，神经元给出不同的反应反馈，这个反馈会传到下一个神经元。比如经过100个神经元的分析 能得到很具体的分析结果。



因此神经网络的能力强度涉及层数和逻辑。



<!--more-->

比如我们输入一句话：“你好“

神经网络如何识别“你好”

可以模拟：

```
第一个神经元用于文字接收

第二的神经元 识别中文

第三个神经元 英语对应的 hello

第四个神经元 判定这是打招呼 需要回应打招呼

第五个神经元 回应“hello”

第六个神经元 我是否要回应更多信息 我自己要介绍自己  my name is AI chat 

第七个神经元 i can help you study how coding program

第八个神经元 检查回复内容是否通畅正确，可读性

第九个神经元  翻译成中文 “你好 我是AI chat 我可以帮助你学习如何编程”
```

![](https://astree.oss-cn-shanghai.aliyuncs.com/opendir/nn-2024-06-13-2100.png)

神经元越多分析得越细 回复的也越多越准确。

神经元就像一个对比纠错函数，让分析内容更准确，回答内容更好。


```
如果模型少了 第六个神经元 回复的就是“你好”

如果模型少了 第九个神经元 回复的就是 “hello my name is AI chat I can help you study how coding program”

如果模型同时少了 第六个和第九个神经元 回复的就是 “hello”
```


实际上AI大模型的神经元层数要多很多 也很复杂。

还要理解复杂语言，如果提问的是“写一段java代码实现打印hello world” 某个神经元肯定是要分析返回一段代码，并且代码符合要求，实现打印hello word。这需要更多的神经元，分析。“写一段” “Java代码” “打印” “实现” 


## 发展及前景

代替人们一些复杂的，变量可控的环境工作，包括艰苦环境下的作业。细分上可以有：

识别判断内容，文字排错 查阅资料 辅助教育

检查 代码优化

图片识别与生成

模拟人作业

构建代码框架

统计数据

活动监督 项目 工程  故障检查



## 目前的AI应用

### 文字生成文字

他主要是LLM（Large Language Model）等语言模型，文字文本处理，返回的也是文字，包括chatgpt 聊天提问。

### 文字转图片

图像生成

openai 的 DALL-E ，通过文字描述生成对应的图片。

chatgpt DALL-E 是比较流行和质量较高的AI应用服务，在国际上经过测试，各种提问，评分最高。

chatgpt 目前能回答大部分提问和返回合理准确的结果。

### 图片转文字

图像内容识别

上传图片，识别图片内容

### 智能驾驶

基于图片识别之上，但是更复杂，保证像人一样开车注视前方内容，并作出判断，判定如何进行动作（行驶或刹车或转弯等）



### 机器人

通过复杂的大量的数据训练，结合强大的硬件技术和机动控制，保证机器人能够像人一样做出反应。





## 面临问题
### GPU资源问题 为什么用到GPU更快
因为用到神经元计算，真实的模型可能涉及多层神经元，多层处理，100层甚至更多。当输入内容“你好”修改成别的，神经元都会作出不同的反应，100层就需要逐个处理100次 很耗时间，但是GPU有多个计算单元，通过并行计算可以快速得出结果（粗略的理解为穷举神经元的所有可能生成一个函数，cpu只能一步一步的计算每一个神经元，导致要执行很多函数，GPU直接将所有可能作为参数列出来，当有不同的输入时，直接通过大量参数一次性并行计算找到对应的结果）

### 科学家的担忧

主要是AI模型包括模拟大脑的神经元但不限于此，按照这个逻辑，如果仅仅是模拟的神经元数量超过人脑的，逻辑上来说就是这个模型比大脑思考能力更强更厉害。

这时候模拟的AI相对于大脑更强大。人能思考到的AI模型也能思考到，并且AI模型还能思考更多人不能思考到的（神经元更多）。

但终归只限于计算的神经元，只限于计算领域，而并没有执行能力，不能像人一样去实践，对想法付出行动。



### 能源发展

人工智能涉及到大量的数据运算，它包含打不限于模拟人脑需要很大量的GPU资源模拟神经元，耗电量大，硬件要求也越来越高。

在说道能源问题，后面如果是经常需要，市场大量使用gpu计算，那么有很大的能源、电量需求来支撑计算，来满足任何与计算有关的项目。而如何获取太阳能源，自然有用能量资源变得尤为重要。因为后续的能源将是风口或者说一直都是，人们从工业革命开始对能源的需求越来越大。



### 风口公司nvidia



英伟达的公司在AI的浪潮中收益匪浅，在这个风口赚的盆满钵满，现在市值提升较大，超过2万亿美金，但我觉得也只是风口问题，竞争力方面并不是垄断性的，命脉也不掌握在他们手里，原因是英伟达只是在风口，占的先机，但不一定也很难垄断AI领域的计算需求。或者说可以被取代。英伟达最初是设计游戏显卡，来满足计算需求，歪打正着。因为游戏画面也是数据大量数据计算，计算景物应该是什么样子的，天空光线应该如何显示等，底层的计算需求与AI计算是类似的。而实现这个大量并行计算的功能，是通过设计多个计算单元，组合在一起。

但实际上这个功能或者实现其他的科技公司花精力研究是可以做到的。而更关键的芯片制造（需要台积电和三星）

上游半导体材料-大量日本企业，计算算法实现-硬件工程师软件工程师，更是关键。

所以nvidia 并不像google 苹果 微软 特斯拉那样的公司那样实力庞大稳定，这就像是一场举行的游戏，普通者别随意入局。